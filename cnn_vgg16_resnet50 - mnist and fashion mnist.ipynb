{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4910ad63-0adc-4265-aa14-efedf6028f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy is already installed.\n",
      "tensorflow is already installed.\n",
      "cv2 is already installed.\n",
      "pywt is already installed.\n",
      "matplotlib is already installed.\n",
      "scipy is already installed.\n",
      "sklearn is already installed.\n",
      "pandas is already installed.\n",
      "All required packages are installed.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Dictionary mapping module names to their pip install package names\n",
    "required_packages = {\n",
    "    'numpy': 'numpy',\n",
    "    'tensorflow': 'tensorflow',\n",
    "    'cv2': 'opencv-python',       # 'cv2' comes from opencv-python\n",
    "    'pywt': 'PyWavelets',         # 'pywt' comes from PyWavelets\n",
    "    'matplotlib': 'matplotlib',\n",
    "    'scipy': 'scipy',\n",
    "    'sklearn': 'scikit-learn',    # scikit-learn provides the 'sklearn' module\n",
    "    'pandas': 'pandas'\n",
    "}\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Installs a package using pip.\"\"\"\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Check for each package and install if missing\n",
    "for module_name, package_name in required_packages.items():\n",
    "    try:\n",
    "        __import__(module_name)\n",
    "        print(f\"{module_name} is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"{module_name} is not installed. Installing {package_name}...\")\n",
    "        install_package(package_name)\n",
    "\n",
    "print(\"All required packages are installed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5b388b-8877-46c1-8b2a-4e6193e1a5fd",
   "metadata": {},
   "source": [
    "# Simple CNN - (MNIST, Fashion MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36f1a6f-097f-4340-b58b-cca30b27892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import pywt\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize grayscale images and reshape\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "X_train = np.expand_dims(X_train, axis=-1)  # Shape: (num_samples, 28, 28, 1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "logging.info(\"Images preprocessed.\")\n",
    "\n",
    "# ------------- 1. Compute FFT Features (Real + Imaginary as 2 Channels) -------------\n",
    "def compute_fft_image(images):\n",
    "    fft_images = []\n",
    "    for img in images:\n",
    "        fft_img = fft2(img[..., 0])  # FFT on the single grayscale channel\n",
    "        fft_real = abs(np.real(fft_img))  # Magnitude part\n",
    "        fft_imag = np.angle(np.imag(fft_img))  # Phase part\n",
    "        fft_image = np.stack([fft_real, fft_imag], axis=-1)  # Shape: (28, 28, 2)\n",
    "        fft_images.append(fft_image)\n",
    "    return np.array(fft_images)\n",
    "\n",
    "# ------------- 2. Compute Wavelet Features (4 Channels) -------------\n",
    "def compute_wavelet_image(images, wavelet='haar', level=1):\n",
    "    wavelet_images = np.empty((images.shape[0], 14, 14, 4), dtype=np.float16)  # Pre-allocate\n",
    "    for i, img in enumerate(images):\n",
    "        coeffs2 = pywt.wavedec2(img[..., 0], wavelet, level=level)  # Wavelet on single channel\n",
    "        cA, (cH, cV, cD) = coeffs2  # Extract coefficients\n",
    "        cA, cH, cV, cD = [cv2.resize(c, (14, 14), interpolation=cv2.INTER_LINEAR) for c in [cA, cH, cV, cD]]\n",
    "        wavelet_images[i] = np.stack([cA, cH, cV, cD], axis=-1)\n",
    "    return wavelet_images\n",
    "\n",
    "# ------------- 3. Define CNN Model -------------\n",
    "def build_cnn(input_shape, num_classes=10):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "# Model Evaluation Function\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    logging.info(f\"{model_name} Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"=== Classification Report for {model_name} ===\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"=== Confusion Matrix for {model_name} ===\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Train CNN on Original MNIST\n",
    "cnn_mnist = build_cnn(input_shape=(28, 28, 1))\n",
    "cnn_mnist.fit(X_train, y_train, epochs=100, validation_split=0.2, callbacks=callbacks, verbose=1)\n",
    "cnn_mnist.save(\"cnn_mnist_model.keras\")\n",
    "evaluate_model(cnn_mnist, X_test, y_test, \"Original MNIST\")\n",
    "\n",
    "# Train CNN on FFT Transformed Images\n",
    "X_train_fft = compute_fft_image(X_train)\n",
    "X_test_fft = compute_fft_image(X_test)\n",
    "cnn_fft = build_cnn(input_shape=(28, 28, 2))\n",
    "cnn_fft.fit(X_train_fft, y_train, epochs=100, validation_split=0.2, callbacks=callbacks, verbose=1)\n",
    "cnn_fft.save(\"cnn_fft_mnist_model.keras\")\n",
    "evaluate_model(cnn_fft, X_test_fft, y_test, \"FFT MNIST\")\n",
    "\n",
    "# Train CNN on Wavelet Transformed Images\n",
    "X_train_wavelet = compute_wavelet_image(X_train)\n",
    "X_test_wavelet = compute_wavelet_image(X_test)\n",
    "cnn_wavelet = build_cnn(input_shape=(14, 14, 4))\n",
    "cnn_wavelet.fit(X_train_wavelet, y_train, epochs=100, validation_split=0.2, callbacks=callbacks, verbose=1)\n",
    "cnn_wavelet.save(\"cnn_wavelet_mnist_model.keras\")\n",
    "evaluate_model(cnn_wavelet, X_test_wavelet, y_test, \"Wavelet MNIST\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ef6300-70fc-47f7-a7a9-186282eba3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import pywt\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize grayscale images and reshape\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "X_train = np.expand_dims(X_train, axis=-1)  # Shape: (num_samples, 28, 28, 1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "logging.info(\"Images preprocessed.\")\n",
    "\n",
    "# ------------- 1. Compute FFT Features (Real + Imaginary as 2 Channels) -------------\n",
    "def compute_fft_image(images):\n",
    "    fft_images = []\n",
    "    for img in images:\n",
    "        fft_img = fft2(img[..., 0])  # FFT on the single grayscale channel\n",
    "        fft_real = abs(np.real(fft_img))  # Magnitude part\n",
    "        fft_imag = np.angle(np.imag(fft_img))  # Phase part\n",
    "        fft_image = np.stack([fft_real, fft_imag], axis=-1)  # Shape: (28, 28, 2)\n",
    "        fft_images.append(fft_image)\n",
    "    return np.array(fft_images)\n",
    "\n",
    "# ------------- 2. Compute Wavelet Features (4 Channels) -------------\n",
    "def compute_wavelet_image(images, wavelet='haar', level=1):\n",
    "    wavelet_images = np.empty((images.shape[0], 14, 14, 4), dtype=np.float16)  # Pre-allocate\n",
    "    for i, img in enumerate(images):\n",
    "        coeffs2 = pywt.wavedec2(img[..., 0], wavelet, level=level)  # Wavelet on single channel\n",
    "        cA, (cH, cV, cD) = coeffs2  # Extract coefficients\n",
    "        cA, cH, cV, cD = [cv2.resize(c, (14, 14), interpolation=cv2.INTER_LINEAR) for c in [cA, cH, cV, cD]]\n",
    "        wavelet_images[i] = np.stack([cA, cH, cV, cD], axis=-1)\n",
    "    return wavelet_images\n",
    "\n",
    "# ------------- 3. Define CNN Model -------------\n",
    "def build_cnn(input_shape, num_classes=10):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
    "    ModelCheckpoint('fashion_mnist_best_model.keras', monitor='val_accuracy', save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "# Model Evaluation Function\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    logging.info(f\"{model_name} Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"=== Classification Report for {model_name} ===\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"=== Confusion Matrix for {model_name} ===\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Train CNN on Original MNIST\n",
    "cnn_mnist = build_cnn(input_shape=(28, 28, 1))\n",
    "cnn_mnist.fit(X_train, y_train, epochs=100, validation_split=0.2, callbacks=callbacks, verbose=1)\n",
    "cnn_mnist.save(\"cnn_fashion_mnist_model.keras\")\n",
    "evaluate_model(cnn_mnist, X_test, y_test, \"Original MNIST\")\n",
    "\n",
    "# Train CNN on FFT Transformed Images\n",
    "X_train_fft = compute_fft_image(X_train)\n",
    "X_test_fft = compute_fft_image(X_test)\n",
    "cnn_fft = build_cnn(input_shape=(28, 28, 2))\n",
    "cnn_fft.fit(X_train_fft, y_train, epochs=100, validation_split=0.2, callbacks=callbacks, verbose=1)\n",
    "cnn_fft.save(\"cnn_fft_fashion_mnist_model.keras\")\n",
    "evaluate_model(cnn_fft, X_test_fft, y_test, \"FFT MNIST\")\n",
    "\n",
    "# Train CNN on Wavelet Transformed Images\n",
    "X_train_wavelet = compute_wavelet_image(X_train)\n",
    "X_test_wavelet = compute_wavelet_image(X_test)\n",
    "cnn_wavelet = build_cnn(input_shape=(14, 14, 4))\n",
    "cnn_wavelet.fit(X_train_wavelet, y_train, epochs=100, validation_split=0.2, callbacks=callbacks, verbose=1)\n",
    "cnn_wavelet.save(\"cnn_wavelet_fashion_mnist_model.keras\")\n",
    "evaluate_model(cnn_wavelet, X_test_wavelet, y_test, \"Wavelet MNIST\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7ce886-f8e3-4319-bffc-8e7129718667",
   "metadata": {},
   "source": [
    "# VGG16 Model - (MNIST, Fashion MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6d8344-f999-4e86-91b2-807e99f0d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import pywt\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# Import VGG16 and its preprocessing function\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize grayscale images and reshape\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "X_train = np.expand_dims(X_train, axis=-1)  # Shape: (num_samples, 28, 28, 1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "logging.info(\"Images preprocessed.\")\n",
    "\n",
    "# ------------- 1. Compute FFT Features (Real + Imaginary as 2 Channels) -------------\n",
    "def compute_fft_image(images):\n",
    "    fft_images = []\n",
    "    for img in images:\n",
    "        fft_img = fft2(img[..., 0])  # FFT on the single grayscale channel\n",
    "        fft_real = abs(np.real(fft_img))  # Magnitude part\n",
    "        fft_imag = np.angle(np.imag(fft_img))  # Phase part\n",
    "        fft_image = np.stack([fft_real, fft_imag], axis=-1)  # Shape: (28, 28, 2)\n",
    "        fft_images.append(fft_image)\n",
    "    return np.array(fft_images)\n",
    "\n",
    "# ------------- 2. Compute Wavelet Features (4 Channels) -------------\n",
    "def compute_wavelet_image(images, wavelet='haar', level=1):\n",
    "    wavelet_images = np.empty((images.shape[0], 14, 14, 4), dtype=np.float16)  # Pre-allocate\n",
    "    for i, img in enumerate(images):\n",
    "        coeffs2 = pywt.wavedec2(img[..., 0], wavelet, level=level)  # Wavelet on single channel\n",
    "        cA, (cH, cV, cD) = coeffs2  # Extract coefficients\n",
    "        cA, cH, cV, cD = [cv2.resize(c, (14, 14), interpolation=cv2.INTER_LINEAR) for c in [cA, cH, cV, cD]]\n",
    "        wavelet_images[i] = np.stack([cA, cH, cV, cD], axis=-1)\n",
    "    return wavelet_images\n",
    "\n",
    "# ------------- 3. Define CNN Model -------------\n",
    "# -------------------- Input Transformer --------------------\n",
    "def build_input_transformer(input_shape, target_shape=(32, 32, 3)):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Resizing(target_shape[0], target_shape[1])(inputs)\n",
    "    if input_shape[-1] != target_shape[-1]:\n",
    "        x = Conv2D(target_shape[-1], (3, 3), padding='same', activation='relu')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=x, name='input_transformer')\n",
    "    return model\n",
    "    \n",
    "def build_vgg16_model(input_shape, num_classes=10, target_shape=(32, 32, 3)):\n",
    "    transformer = build_input_transformer(input_shape, target_shape)\n",
    "    inputs = transformer.input\n",
    "    x = transformer.output\n",
    "    x = tf.keras.layers.Lambda(lambda img: preprocess_input(img * 255.0))(x)\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=target_shape)\n",
    "    base_model.trainable = False  # Freeze VGG16 layers\n",
    "    x = base_model(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name='vgg16_model')\n",
    "    model.compile(optimizer=Adam(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
    "    ModelCheckpoint('vgg16_best_mnist_model.keras', monitor='val_accuracy', save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "# Model Evaluation Function\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    logging.info(f\"{model_name} Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"=== Classification Report for {model_name} ===\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"=== Confusion Matrix for {model_name} ===\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Train CNN on Original MNIST\n",
    "cnn_mnist = build_vgg16_model(input_shape=(28, 28, 1))\n",
    "cnn_mnist.fit(X_train, y_train, epochs=100, validation_split=0.2, callbacks=callbacks, verbose=1)\n",
    "cnn_mnist.save(\"vgg16_mnist_model.keras\")\n",
    "evaluate_model(cnn_mnist, X_test, y_test, \"vgg16 Original MNIST\")\n",
    "\n",
    "# Train CNN on FFT Transformed Images\n",
    "X_train_fft = compute_fft_image(X_train)\n",
    "X_test_fft = compute_fft_image(X_test)\n",
    "cnn_fft = build_vgg16_model(input_shape=(28, 28, 2))\n",
    "cnn_fft.fit(X_train_fft, y_train, epochs=100, validation_split=0.2, callbacks=callbacks, verbose=1)\n",
    "cnn_fft.save(\"vgg16_fft_mnist_model.keras\")\n",
    "evaluate_model(cnn_fft, X_test_fft, y_test, \"vgg16 FFT MNIST\")\n",
    "\n",
    "# Train CNN on Wavelet Transformed Images\n",
    "X_train_wavelet = compute_wavelet_image(X_train)\n",
    "X_test_wavelet = compute_wavelet_image(X_test)\n",
    "cnn_wavelet = build_vgg16_model(input_shape=(14, 14, 4))\n",
    "cnn_wavelet.fit(X_train_wavelet, y_train, epochs=100, validation_split=0.2, callbacks=callbacks, verbose=1)\n",
    "cnn_wavelet.save(\"vgg16_wavelet_mnist_model.keras\")\n",
    "evaluate_model(cnn_wavelet, X_test_wavelet, y_test, \"vgg16 Wavelet MNIST\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231e9280-91e3-4349-9d93-5c989252a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import pywt\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Import VGG16 and its preprocessing function\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize grayscale images and reshape\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "X_train = np.expand_dims(X_train, axis=-1)  # Shape: (num_samples, 28, 28, 1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "logging.info(\"Images preprocessed.\")\n",
    "\n",
    "# ------------- 1. Compute FFT Features (Real + Imaginary as 2 Channels) -------------\n",
    "def compute_fft_image(images):\n",
    "    fft_images = []\n",
    "    for img in images:\n",
    "        fft_img = fft2(img[..., 0])  # FFT on the single grayscale channel\n",
    "        fft_real = abs(np.real(fft_img))  # Magnitude part\n",
    "        fft_imag = np.angle(np.imag(fft_img))  # Phase part\n",
    "        fft_image = np.stack([fft_real, fft_imag], axis=-1)  # Shape: (28, 28, 2)\n",
    "        fft_images.append(fft_image)\n",
    "    return np.array(fft_images)\n",
    "\n",
    "# ------------- 2. Compute Wavelet Features (4 Channels) -------------\n",
    "def compute_wavelet_image(images, wavelet='haar', level=1):\n",
    "    wavelet_images = np.empty((images.shape[0], 14, 14, 4), dtype=np.float16)  # Pre-allocate\n",
    "    for i, img in enumerate(images):\n",
    "        coeffs2 = pywt.wavedec2(img[..., 0], wavelet, level=level)  # Wavelet on single channel\n",
    "        cA, (cH, cV, cD) = coeffs2  # Extract coefficients\n",
    "        cA, cH, cV, cD = [cv2.resize(c, (14, 14), interpolation=cv2.INTER_LINEAR) for c in [cA, cH, cV, cD]]\n",
    "        wavelet_images[i] = np.stack([cA, cH, cV, cD], axis=-1)\n",
    "    return wavelet_images\n",
    "\n",
    "# ------------- 3. Define CNN Model -------------\n",
    "def build_input_transformer(input_shape, target_shape=(32, 32, 3)):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Resizing(target_shape[0], target_shape[1])(inputs)\n",
    "    if input_shape[-1] != target_shape[-1]:\n",
    "        x = Conv2D(target_shape[-1], (3, 3), padding='same', activation='relu')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=x, name='input_transformer')\n",
    "    return model\n",
    "    \n",
    "def build_vgg16_model(input_shape, num_classes=10, target_shape=(32, 32, 3)):\n",
    "    transformer = build_input_transformer(input_shape, target_shape)\n",
    "    inputs = transformer.input\n",
    "    x = transformer.output\n",
    "    x = tf.keras.layers.Lambda(lambda img: preprocess_input(img * 255.0))(x)\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=target_shape)\n",
    "    base_model.trainable = False  # Freeze VGG16 layers\n",
    "    x = base_model(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name='vgg16_model')\n",
    "    model.compile(optimizer=Adam(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
    "    ModelCheckpoint('vgg16_fashion_mnist_best_model.keras', monitor='val_accuracy', save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "# Model Evaluation Function\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    logging.info(f\"{model_name} Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"=== Classification Report for {model_name} ===\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"=== Confusion Matrix for {model_name} ===\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Train CNN on Original MNIST\n",
    "cnn_mnist = build_vgg16_model(input_shape=(28, 28, 1))\n",
    "cnn_mnist.fit(X_train, y_train, epochs=100, validation_split=0.2, callbacks=callbacks, verbose=1)\n",
    "cnn_mnist.save(\"vgg16_fashion_mnist_model.keras\")\n",
    "evaluate_model(cnn_mnist, X_test, y_test, \"vgg16 Original MNIST\")\n",
    "\n",
    "# Train CNN on FFT Transformed Images\n",
    "X_train_fft = compute_fft_image(X_train)\n",
    "X_test_fft = compute_fft_image(X_test)\n",
    "cnn_fft = build_vgg16_model(input_shape=(28, 28, 2))\n",
    "cnn_fft.fit(X_train_fft, y_train, epochs=100, validation_split=0.2, callbacks=callbacks, verbose=1)\n",
    "cnn_fft.save(\"vgg16_fft_fashion_mnist_model.keras\")\n",
    "evaluate_model(cnn_fft, X_test_fft, y_test, \"vgg16 FFT MNIST\")\n",
    "\n",
    "# Train CNN on Wavelet Transformed Images\n",
    "X_train_wavelet = compute_wavelet_image(X_train)\n",
    "X_test_wavelet = compute_wavelet_image(X_test)\n",
    "cnn_wavelet = build_vgg16_model(input_shape=(14, 14, 4))\n",
    "cnn_wavelet.fit(X_train_wavelet, y_train, epochs=100, validation_split=0.2, callbacks=callbacks, verbose=1)\n",
    "cnn_wavelet.save(\"vgg16_wavelet_fashion_mnist_model.keras\")\n",
    "evaluate_model(cnn_wavelet, X_test_wavelet, y_test, \"vgg16 Wavelet MNIST\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0569b3-d2e2-4f44-8f4c-793e7d7b3087",
   "metadata": {},
   "source": [
    "# Resnet50 Model - (MNIST, Fashion MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4c9127-6b4d-4cb7-b1dd-94311855a1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import pywt\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize grayscale images and reshape\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "X_train = np.expand_dims(X_train, axis=-1)  # Shape: (num_samples, 28, 28, 1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "logging.info(\"Images preprocessed.\")\n",
    "\n",
    "# ------------- 1. Compute FFT Features (Real + Imaginary as 2 Channels) -------------\n",
    "def compute_fft_image(images):\n",
    "    fft_images = []\n",
    "    for img in images:\n",
    "        fft_img = fft2(img[..., 0])  # FFT on the single grayscale channel\n",
    "        fft_real = abs(np.real(fft_img))  # Magnitude part\n",
    "        fft_imag = np.angle(np.imag(fft_img))  # Phase part\n",
    "        fft_image = np.stack([fft_real, fft_imag], axis=-1)  # Shape: (28, 28, 2)\n",
    "        fft_images.append(fft_image)\n",
    "    return np.array(fft_images)\n",
    "\n",
    "# ------------- 2. Compute Wavelet Features (4 Channels) -------------\n",
    "def compute_wavelet_image(images, wavelet='haar', level=1):\n",
    "    wavelet_images = np.empty((images.shape[0], 14, 14, 4), dtype=np.float16)  # Pre-allocate\n",
    "    for i, img in enumerate(images):\n",
    "        coeffs2 = pywt.wavedec2(img[..., 0], wavelet, level=level)  # Wavelet on single channel\n",
    "        cA, (cH, cV, cD) = coeffs2  # Extract coefficients\n",
    "        cA, cH, cV, cD = [cv2.resize(c, (14, 14), interpolation=cv2.INTER_LINEAR) for c in [cA, cH, cV, cD]]\n",
    "        wavelet_images[i] = np.stack([cA, cH, cV, cD], axis=-1)\n",
    "    return wavelet_images\n",
    "\n",
    "# ------------- 3. Define CNN Model -------------\n",
    "# -------------------- Input Transformer --------------------\n",
    "def build_input_transformer(input_shape, target_shape=(224, 224, 3)):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Resizing(target_shape[0], target_shape[1])(inputs)\n",
    "    if input_shape[-1] != target_shape[-1]:\n",
    "        x = Conv2D(target_shape[-1], (3, 3), padding='same', activation='relu')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=x, name='input_transformer')\n",
    "    return model\n",
    "    \n",
    "def build_resnet_model(input_shape, num_classes=10, target_shape=(224, 224, 3)):\n",
    "    transformer = build_input_transformer(input_shape, target_shape)\n",
    "    inputs = transformer.input\n",
    "    x = transformer.output\n",
    "    x = tf.keras.layers.Lambda(lambda img: preprocess_input(img * 255.0))(x)\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=target_shape)\n",
    "    base_model.trainable = False  # Freeze ResNet layers\n",
    "    x = base_model(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name='resnet_model')\n",
    "    model.compile(optimizer=Adam(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
    "    ModelCheckpoint('resnet_best_mnist_model.keras', monitor='val_accuracy', save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "# Model Evaluation Function\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    logging.info(f\"{model_name} Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"=== Classification Report for {model_name} ===\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"=== Confusion Matrix for {model_name} ===\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Train CNN on Original MNIST\n",
    "cnn_mnist = build_resnet_model(input_shape=(28, 28, 1))\n",
    "cnn_mnist.fit(X_train, y_train, epochs=100, validation_split=0.2, callbacks=callbacks, verbose=1)\n",
    "cnn_mnist.save(\"resnet_mnist_model.keras\")\n",
    "evaluate_model(cnn_mnist, X_test, y_test, \"resnet Original MNIST\")\n",
    "\n",
    "# Train CNN on FFT Transformed Images\n",
    "X_train_fft = compute_fft_image(X_train)\n",
    "X_test_fft = compute_fft_image(X_test)\n",
    "cnn_fft = build_resnet_model(input_shape=(28, 28, 2))\n",
    "cnn_fft.fit(X_train_fft, y_train, epochs=100, validation_split=0.2, callbacks=callbacks, verbose=1)\n",
    "cnn_fft.save(\"resnet_fft_mnist_model.keras\")\n",
    "evaluate_model(cnn_fft, X_test_fft, y_test, \"resnet FFT MNIST\")\n",
    "\n",
    "# Train CNN on Wavelet Transformed Images\n",
    "X_train_wavelet = compute_wavelet_image(X_train)\n",
    "X_test_wavelet = compute_wavelet_image(X_test)\n",
    "cnn_wavelet = build_resnet_model(input_shape=(14, 14, 4))\n",
    "cnn_wavelet.fit(X_train_wavelet, y_train, epochs=100, validation_split=0.2, callbacks=callbacks, verbose=1)\n",
    "cnn_wavelet.save(\"resnet_wavelet_mnist_model.keras\")\n",
    "evaluate_model(cnn_wavelet, X_test_wavelet, y_test, \"resnet Wavelet MNIST\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c448789-53b3-4b86-8466-71aada19bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import pywt\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize grayscale images and reshape\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "X_train = np.expand_dims(X_train, axis=-1)  # Shape: (num_samples, 28, 28, 1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "logging.info(\"Images preprocessed.\")\n",
    "\n",
    "# ------------- 1. Compute FFT Features (Real + Imaginary as 2 Channels) -------------\n",
    "def compute_fft_image(images):\n",
    "    fft_images = []\n",
    "    for img in images:\n",
    "        fft_img = fft2(img[..., 0])  # FFT on the single grayscale channel\n",
    "        fft_real = abs(np.real(fft_img))  # Magnitude part\n",
    "        fft_imag = np.angle(np.imag(fft_img))  # Phase part\n",
    "        fft_image = np.stack([fft_real, fft_imag], axis=-1)  # Shape: (28, 28, 2)\n",
    "        fft_images.append(fft_image)\n",
    "    return np.array(fft_images)\n",
    "\n",
    "# ------------- 2. Compute Wavelet Features (4 Channels) -------------\n",
    "def compute_wavelet_image(images, wavelet='haar', level=1):\n",
    "    wavelet_images = np.empty((images.shape[0], 14, 14, 4), dtype=np.float16)  # Pre-allocate\n",
    "    for i, img in enumerate(images):\n",
    "        coeffs2 = pywt.wavedec2(img[..., 0], wavelet, level=level)  # Wavelet on single channel\n",
    "        cA, (cH, cV, cD) = coeffs2  # Extract coefficients\n",
    "        cA, cH, cV, cD = [cv2.resize(c, (14, 14), interpolation=cv2.INTER_LINEAR) for c in [cA, cH, cV, cD]]\n",
    "        wavelet_images[i] = np.stack([cA, cH, cV, cD], axis=-1)\n",
    "    return wavelet_images\n",
    "\n",
    "# ------------- 3. Define CNN Model -------------\n",
    "def build_input_transformer(input_shape, target_shape=(224, 224, 3)):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Resizing(target_shape[0], target_shape[1])(inputs)\n",
    "    if input_shape[-1] != target_shape[-1]:\n",
    "        x = Conv2D(target_shape[-1], (3, 3), padding='same', activation='relu')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=x, name='input_transformer')\n",
    "    return model\n",
    "    \n",
    "def build_resnet_model(input_shape, num_classes=10, target_shape=(224, 224, 3)):\n",
    "    transformer = build_input_transformer(input_shape, target_shape)\n",
    "    inputs = transformer.input\n",
    "    x = transformer.output\n",
    "    x = tf.keras.layers.Lambda(lambda img: preprocess_input(img * 255.0))(x)\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=target_shape)\n",
    "    base_model.trainable = False  # Freeze ResNet layers\n",
    "    x = base_model(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name='resnet_model')\n",
    "    model.compile(optimizer=Adam(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
    "    ModelCheckpoint('vgg16_fashion_mnist_best_model.keras', monitor='val_accuracy', save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "# Model Evaluation Function\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    logging.info(f\"{model_name} Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"=== Classification Report for {model_name} ===\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"=== Confusion Matrix for {model_name} ===\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Train CNN on Original MNIST\n",
    "cnn_mnist = build_resnet_model(input_shape=(28, 28, 1))\n",
    "cnn_mnist.fit(X_train, y_train, epochs=100, validation_split=0.2, callbacks=callbacks, verbose=1)\n",
    "cnn_mnist.save(\"resnet_fashion_mnist_model.keras\")\n",
    "evaluate_model(cnn_mnist, X_test, y_test, \"resnet Original MNIST\")\n",
    "\n",
    "# Train CNN on FFT Transformed Images\n",
    "X_train_fft = compute_fft_image(X_train)\n",
    "X_test_fft = compute_fft_image(X_test)\n",
    "cnn_fft = build_resnet_model(input_shape=(28, 28, 2))\n",
    "cnn_fft.fit(X_train_fft, y_train, epochs=100, validation_split=0.2, callbacks=callbacks, verbose=1)\n",
    "cnn_fft.save(\"resnet_fft_fashion_mnist_model.keras\")\n",
    "evaluate_model(cnn_fft, X_test_fft, y_test, \"resnet FFT MNIST\")\n",
    "\n",
    "# Train CNN on Wavelet Transformed Images\n",
    "X_train_wavelet = compute_wavelet_image(X_train)\n",
    "X_test_wavelet = compute_wavelet_image(X_test)\n",
    "cnn_wavelet = build_resnet_model(input_shape=(14, 14, 4))\n",
    "cnn_wavelet.fit(X_train_wavelet, y_train, epochs=100, validation_split=0.2, callbacks=callbacks, verbose=1)\n",
    "cnn_wavelet.save(\"resnet_wavelet_fashion_mnist_model.keras\")\n",
    "evaluate_model(cnn_wavelet, X_test_wavelet, y_test, \"resnet Wavelet MNIST\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
